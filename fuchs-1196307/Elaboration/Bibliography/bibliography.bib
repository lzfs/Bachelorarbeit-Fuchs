@article{li_time-flight_2014,
  title     = {Time-of-flight camera--an introduction},
  url       = {https://www.ti.com/lit/wp/sloa190b/sloa190b.pdf},
  author    = {Li, Larry and others},
  journal   = {Technical white paper},
  note      = {SLOA190B},
  year      = {2014},
  publisher = {Citeseer},
  file      = {download.pdf:C\:\\Users\\laure\\Zotero\\storage\\JTUN79DR\\download.pdf:application/pdf}
}

@article{marin_multi-camera_2019,
  title        = {A multi-camera dataset for depth estimation in an indoor scenario},
  url          = {https://linkinghub.elsevier.com/retrieve/pii/S2352340919309746},
  doi          = {10.1016/j.dib.2019.104619},
  abstract     = {Time-of-Flight ({ToF}) sensors and stereo vision systems are two of the most diffused depth acquisition devices for commercial and industrial applications. They share complementary strengths and weaknesses. For this reason, the combination of data acquired from these devices can improve the ﬁnal depth estimation accuracy. This paper introduces a dataset acquired with a multi-camera system composed by a Microsoft Kinect v2 {ToF} sensor, an Intel {RealSense} R200 active stereo sensor and a Stereolabs {ZED} passive stereo camera system. The acquired scenes include indoor settings with different external lighting conditions. The depth ground truth has been acquired for each scene of the dataset using a line laser. The data can be used for developing fusion and denoising algorithms for depth estimation and test with different lighting conditions. A subset of the data has already been used for the experimental evaluation of the work "Stereo and {ToF} Data Fusion by Learning from Synthetic Data".},
  pages        = {104619},
  journal      = {Data in Brief},
  shortjournal = {Data in Brief},
  author       = {Marin, Giulio and Agresti, Gianluca and Minto, Ludovico and Zanuttigh, Pietro},
  urldate      = {2022-01-24},
  year         = {2019},
  file         = {Marin et al. - 2019 - A multi-camera dataset for depth estimation in an .pdf:C\:\\Users\\laure\\Zotero\\storage\\N7ZFGS35\\Marin et al. - 2019 - A multi-camera dataset for depth estimation in an .pdf:application/pdf}
}

@article{mohammadzade_dynamic_2021,
  title        = {Dynamic Time Warping-Based Features With Class-Specific Joint Importance Maps for Action Recognition Using Kinect Depth Sensor},
  doi          = {10.1109/JSEN.2021.3051497},
  abstract     = {This paper proposes a novel 3D action recognition technique that uses time-series information extracted from depth image sequences for use in systems of human daily activity monitoring. To this end, each action is represented as a multi-dimensional time series, where each dimension represents the position variation of one skeleton joint over time. The time series is then mapped onto a vector space using Dynamic Time Warping ({DTW}) distance. Furthermore, to employ the correlation-distinctiveness relationship of the sequences in recognition, this vector space is remapped onto a discriminative space using the regularized Fisher method, where final decisions about the actions are made. Unlike other available methods, the time-warping used in the mapping strategy makes the feature space robust to temporal variations of the motion sequences. Moreover, our method eliminates the need for a complicated design method for extracting the static and dynamic information of a motion sequence. Furthermore, most existing methods treat all skeletal joints identically for different actions, while some joints are more discriminative to distinguish a specific action. Thanks to the nature of the proposed features, we propose to use a separate set of discriminative joints, called joint importance map for each class of action. Evaluation results on four well-known datasets, {TST}, {UTKinect}, {UCFKinect}, and {NTU} {RGB}+D show competitive performance with the state-of-the-art methods in human action recognition.},
  pages        = {9300--9313},
  journaltitle = {{IEEE} Sensors Journal},
  author       = {Mohammadzade, Hoda and Hosseini, Soheil and Rezaei-Dastjerdehei, Mohammad Reza and Tabejamaat, Mohsen},
  year         = {2021},
  note         = {Conference Name: {IEEE} Sensors Journal},
  keywords     = {Sensors, Skeleton, Feature extraction, Kernel, 3D action recognition, Data mining, dynamic time warping, feature space, joint importance map, time series, Time series analysis, Training},
  file         = {IEEE Xplore Full Text PDF:C\:\\Users\\laure\\Zotero\\storage\\UPKNM2DM\\Mohammadzade et al. - 2021 - Dynamic Time Warping-Based Features With Class-Spe.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\laure\\Zotero\\storage\\CF2H68FT\\9321506.html:text/html}
}

@article{tolgyessy_evaluation_2021,
  title    = {Evaluation of the Azure Kinect and Its Comparison to Kinect V1 and Kinect V2},
  rights   = {http://creativecommons.org/licenses/by/3.0/},
  url      = {https://www.mdpi.com/1424-8220/21/2/413},
  doi      = {10.3390/s21020413},
  abstract = {The Azure Kinect is the successor of Kinect v1 and Kinect v2. In this paper we perform brief data analysis and comparison of all Kinect versions with focus on precision (repeatability) and various aspects of noise of these three sensors. Then we thoroughly evaluate the new Azure Kinect; namely its warm-up time, precision (and sources of its variability), accuracy (thoroughly, using a robotic arm), reflectivity (using 18 different materials), and the multipath and flying pixel phenomenon. Furthermore, we validate its performance in both indoor and outdoor environments, including direct and indirect sun conditions. We conclude with a discussion on its improvements in the context of the evolution of the Kinect sensor. It was shown that it is crucial to choose well designed experiments to measure accuracy, since the {RGB} and depth camera are not aligned. Our measurements confirm the officially stated values, namely standard deviation ≤17 mm, and distance error {\textless}11 mm in up to 3.5 m distance from the sensor in all four supported modes. The device, however, has to be warmed up for at least 40–50 min to give stable results. Due to the time-of-flight technology, the Azure Kinect cannot be reliably used in direct sunlight. Therefore, it is convenient mostly for indoor applications.},
  pages    = {413},
  journal  = {Sensors},
  author   = {Tölgyessy, Michal and Dekan, Martin and Chovanec, Luboš and Hubinský, Peter},
  urldate  = {2022-02-28},
  year     = {2021},
  keywords = {gesture recognition, Kinect, 3D scanning, Azure Kinect, depth imaging, {HRI} (human–robot interaction), mapping, object recognition, robotics, {SLAM} (simultaneous localization and mapping)},
  file     = {Full Text PDF:C\:\\Users\\laure\\Zotero\\storage\\L9DBS9A9\\Tölgyessy et al. - 2021 - Evaluation of the Azure Kinect and Its Comparison .pdf:application/pdf;Snapshot:C\:\\Users\\laure\\Zotero\\storage\\BKMFH7GL\\413.html:text/html}
}

@misc{unibw_honeypot-effekt_2021,
  title   = {Honeypot-Effekt an interaktiven Ambient Displays ({HoPE}) — Inf2},
  author  = {UniBw},
  year    = {2021},
  url     = {https://www.unibw.de/inf2/forschung/projekte/hope},
  urldate = {2022-02-28},
  file    = {Honeypot-Effekt an interaktiven Ambient Displays (HoPE) — Inf2:C\:\\Users\\laure\\Zotero\\storage\\X7DCH7FG\\hope.html:text/html}
}

@article{ali_clustering_2019,
  title      = {Clustering and Classification for Time Series Data in Visual Analytics: A Survey},
  doi        = {10.1109/ACCESS.2019.2958551},
  shorttitle = {Clustering and Classification for Time Series Data in Visual Analytics},
  abstract   = {Visual analytics for time series data has received a considerable amount of attention. Different approaches have been developed to understand the characteristics of the data and obtain meaningful statistics in order to explore the underlying processes, identify and estimate trends, make decisions and predict the future. The machine learning and visualization areas share a focus on extracting information from data. In this paper, we consider not only automatic methods but also interactive exploration. The ability to embed efficient machine learning techniques (clustering and classification) in interactive visualization systems is highly desirable in order to gain the most from both humans and computers. We present a literature review of some of the most important publications in the field and classify over 60 published papers from six different perspectives. This review intends to clarify the major concepts with which clustering or classification algorithms are used in visual analytics for time series data and provide a valuable guide for both new researchers and experts in the emerging field of integrating machine learning techniques into visual analytics.},
  pages      = {181314--181338},
  journal    = {{IEEE} Access},
  author     = {Ali, Mohammed and Alqahtani, Ali and Jones, Mark W. and Xie, Xianghua},
  year       = {2019},
  note       = {Conference Name: {IEEE} Access},
  keywords   = {Time series analysis, classification, clustering, Clustering algorithms, Data visualization, Machine learning, Machine learning algorithms, Time series data, visual analytics, Visual analytics, visualization},
  file       = {IEEE Xplore Full Text PDF:C\:\\Users\\laure\\Zotero\\storage\\RYFX7P8E\\Ali et al. - 2019 - Clustering and Classification for Time Series Data.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\laure\\Zotero\\storage\\7B9ZAE7A\\8930535.html:text/html}
}

@inproceedings{mai_audience_2018,
  title     = {The Audience Funnel for Head-Mounted Displays in Public Environments},
  booktitle = {2018 IEEE 4th Workshop on Everyday Virtual Reality (WEVR)},
  abstract  = {In the earlier days {HMD} based experiences were closely coupled to a researcher who took care for the system and the users. In contrast, in commercial application areas, the {HMD} is presented in a public environment without anybody being present. In order to foster systematic investigation and approaches to evaluate the system design of {HMDs} –e.g. how to care for the users physical security and their feeling of being secure– and {HMD} experiences, we propose to learn from the research on public displays. To investigate the challenges of {HMD} usage in public spaces, existing knowledge can accelerate our understanding on how to attract people’s attention, motivate people to use {HMDs} and overcome barriers that prevent people from using {HMDs} presented in public. We propose an adaption of the audience funnel concept on the usage of {HMDs}, discuss differences and present indications from a ﬁeld study that the audience funnel concept might hold in the usage of {HMDs}.},
  pages     = {5},
  author    = {Mai, Christian and Hußmann, Heinrich},
  year      = {2018},
  file      = {Mai und Hußmann - The Audience Funnel for Head-Mounted Displays in P.pdf:C\:\\Users\\laure\\Zotero\\storage\\ASVX4PCU\\Mai und Hußmann - The Audience Funnel for Head-Mounted Displays in P.pdf:application/pdf}
}

@inproceedings{wouters_uncovering_2016,
  title      = {Uncovering the Honeypot Effect: How Audiences Engage with Public Interactive Systems},
  url        = {https://dl.acm.org/doi/10.1145/2901790.2901796},
  doi        = {10.1145/2901790.2901796},
  shorttitle = {Uncovering the Honeypot Effect},
  abstract   = {In {HCI}, the honeypot effect describes how people interacting with a system passively stimulate passers-by to observe, approach and engage in an interaction. Previous research has revealed the successive engagement phases and zones of the honeypot effect. However, there is little insight into: 1) how people are stimulated to transition between phases; 2) what aspects drive the honeypot effect apart from watching others; and 3) what constraints affect its selfreinforcing performance. In this paper, we discuss the honeypot effect as a spatiotemporal model of trajectories and influences. We introduce the Honeypot Model based on the analysis of observations and interaction logs from Encounters, a public installation that interactively translated bodily movements into a dynamic visual and sonic output. In providing a model that describes trajectories and influences of audience engagement in public interactive systems, our paper seeks to inform researchers and designers to consider contextual, spatial and social factors that influence audience engagement.},
  eventtitle = {{DIS} '16: Designing Interactive Systems Conference 2016},
  pages      = {5--16},
  booktitle  = {Proceedings of the 2016 {ACM} Conference on Designing Interactive Systems},
  author     = {Wouters, Niels and Downs, John and Harrop, Mitchell and Cox, Travis and Oliveira, Eduardo and Webber, Sarah and Vetere, Frank and Vande Moere, Andrew},
  urldate    = {2022-02-28},
  year       = {2016},
  file       = {Wouters et al. - 2016 - Uncovering the Honeypot Effect How Audiences Enga.pdf:C\:\\Users\\laure\\Zotero\\storage\\HFPXM9ZS\\Wouters et al. - 2016 - Uncovering the Honeypot Effect How Audiences Enga.pdf:application/pdf}
}

@inproceedings{mankoff_heuristic_2003,
  title        = {Heuristic Evaluation of Ambient Displays},
  booktitle    = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  doi          = {10.1145/642611.642642},
  abstract     = {We present a technique for evaluating the usability and eﬀectiveness of ambient displays. Ambient displays are abstract and aesthetic peripheral displays portraying non-critical information on the periphery of a user’s attention. Although many innovative displays have been published, little existing work has focused on their evaluation, in part because evaluation of ambient displays is diﬃcult and costly. We adapted a low-cost evaluation technique, heuristic evaluation, for use with ambient displays. With the help of ambient display designers, we deﬁned a modiﬁed set of heuristics. We compared the performance of Nielsen’s heuristics and our heuristics on two ambient displays. Evaluators using our heuristics found more, severe problems than evaluators using Nielsen’s heuristics. Additionally, when using our heuristics, 3-5 evaluators were able to identify 40-60\% of known usability issues. This implies that heuristic evaluation is an eﬀective technique for identifying usability issues with ambient displays.},
  pages        = {169--176},
  journaltitle = {{NEW} {HORIZONS}},
  author       = {Mankoﬀ, Jennifer and Dey, Anind K and Hsieh, Gary and Kientz, Julie and Lederer, Scott and Ames, Morgan},
  year         = {2003},
  file         = {Mankoﬀ et al. - 2003 - Heuristic Evaluation of Ambient Displays.pdf:C\:\\Users\\laure\\Zotero\\storage\\FTM6Z64S\\Mankoﬀ et al. - 2003 - Heuristic Evaluation of Ambient Displays.pdf:application/pdf}
}

@misc{windows-developer-center_microsoft_corporation_human_2014,
  title   = {Human Interface Guidelines v2.0},
  author  = {Microsoft},
  url     = {https://download.microsoft.com/download/6/7/6/676611B4-1982-47A4-A42E-4CF84E1095A8/KinectHIG.2.0.pdf},
  editor  = {{Windows-Developer-Center Microsoft Corporation}},
  urldate = {2022-03-01},
  year    = {2014},
  file    = {KinectHIG.2.0.pdf:C\:\\Users\\laure\\Zotero\\storage\\FDLD8UD8\\KinectHIG.2.0.pdf:application/pdf}
}

@mastersthesis{temiz_konzeption_2022,
  title  = {Konzeption und Implementierung eines Datenanalyse-Werkzeugs für Body-Tracking-Kameras},
  pages  = {78},
  type   = {Bachelor's thesis},
  school = {Universität der Bundeswehr München},
  author = {Temiz, Joel},
  year   = {2022},
  file   = {Konzeption und Implementierung eines Datenanalyse-.pdf:C\:\\Users\\laure\\Zotero\\storage\\P7B66VHY\\Konzeption und Implementierung eines Datenanalyse-.pdf:application/pdf}
}