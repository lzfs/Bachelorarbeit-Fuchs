\chapter{Konzeption}
\label{chapter4}
Vor der eigentlichen Implementierung erfolgt nun eine Konzeption.
Damit wird elaboriert, welche Anforderungen an die Software gestellt werden
und wie die Implementierung erfolgen soll.
Etwaige Ungereimtheiten und Probleme können so frühzeitig erkannt werden.


\section{Anforderungsanalyse}
\label{4-Anforderungsanalyse}
Es soll ein System implementiert werden,
welches Kinect-Bewegungsdaten mithilfe von hierarchischem Clustering
und \ac{DTW} als Distanzmetrik gruppiert.
Dieses Tool kann im Rahmen des HoPE-Projekts genutzt werden,
um große Datensätze auf wiederkehrende Bewegungsabläufe bei der Interaktion mit Wandbildschirmen
zu untersuchen.
Es gibt sogenannte \emph{funktionale Anforderungen} und \emph{nicht-funktionale Anforderungen},
die das System erfüllen muss.
Letztere beinhalten beispielsweise Anforderungen zu Benutzbarkeit, Effizienz oder Portierbarkeit.
Funktionale Anforderungen beschreiben hingegen die primären Features des Systems.

\subsection{Nicht-funktionale Anforderungen}
\label{4-NichtFunktionaleAnforderungen}
Bei der Wahl der Programmiersprache und verwendeten Frameworks
existieren keine speziellen Vorgaben.
Das Tool sollte allerdings ohne großen Installationsaufwand nutzbar sein
und daher nach Möglichkeit eine stark verbreitete Programmiersprache nutzen.
Bei der Implementierung fällt daher die Wahl auf Java in der Version 14.
Dabei sollen auch keine externen Bibliotheken genutzt werden.
An die Effizienz gibt es ebenfalls keine besonderen Anforderungen,
da die Auswertung der Daten nur einmalig zu einem späteren Zeitpunkt erfolgt.
Eine Echtzeitauswertung ist nicht geplant.
Da zu lange Wartezeiten, aber die Nutzbarkeit des Tools einschränken,
sollen berechnete Kosten in einer geeigneten Datenstruktur zwischengespeichert werden.
So können im darauffolgenden Iterationsschritt viele Berechnungsschritte eingespart werden.
Das Tool sollte durch wenige Anpassungen auch auf Datensätze anderer Tiefenkameras angewandt werden können.
Um dieses Ziel zu erreichen, wird die Software von Beginn an möglichst generisch entwickelt.
Zu allen Bestandteilen des Tools existiert daher ein Interface.
Bei Bedarf können so einfach neue Implementierungen,
die den Anforderungen anderer Datensätze entsprechen, ergänzt werden.

\subsection{Funktionale Anforderungen}
\label{4-FunktionaleAnforderungen}
Die Software kümmert sich um den Input.
Ein Datensatz kann aus Textdateien eingelesen und in passenden Datenobjekten abgespeichert werden.
Das Tool soll ein Clustering mittels hierarchischem Clustering wie in \autoref{3-Clustering} beschrieben anbieten.
Dabei ist der Threshold für das Mergen von zwei Clustern vom Nutzer konfigurierbar.
Als Distanzmetrik wird \ac{DTW} (\autoref{3-DTW}) genutzt.
Dabei ist konfigurierbar, welche Attribute des Datensatzes für den Vergleich genutzt werden.
Zur Berechnung der Distanz zwischen zwei Punkten wird die euklidische Distanz verwendet.
Allerdings können auch hier einfach weitere Funktionen ergänzt werden.
Per Startparameter kann entschieden werden, welche dieser Funktionen für die Berechnung verwendet wird.
Zudem besitzt das Output-Funktionalitäten.
Die gefundenen Cluster werden in einer Textdatei aufgelistet.
Jedes Cluster erhält einen eindeutigen Namen und eine Liste aller Records die zusammengeführt wurden.
Für ein erleichtertes Verständnis der Cluster wird auch eine primitive Visualiserung der Cluster angeboten.
Hier werden die Laufpfade aus der Vogelperspektive dargestellt.
Falls sich mehrere Records im Cluster befinden wird der Mittelwert der Attribute visualisiert.
Die starke Konfigurierbarkeit wird durch eine \emph{config-file} erreicht,
die der Nutzer beim Start der Anwendung übergeben kann.
Sie enthält folgende Parameter:

\begin{center}
    \begin{tabular}{ |c|c| } 
     \hline
     Attributname & Beschreibung \\
     \hline \hline
     inputPath & Pfad zum Datensatz. \\
     \hline
     outputPath & Pfad zum Ablegen der Output-Dateien.  \\
     \hline
     separator & Trennzeichen zwischen den Attributen. \\
     \hline
     datasetType & Art des vorliegenden Datensatzes. \\
     \hline
     threshold & Grenzwert für das Zusammenführen von Clustern. \\
     \hline
     attributes & Vorhandene Attribute. \\
     \hline
     usedAttributes & Attribute, die zum Vergleich genutzt werden. \\
     \hline
     distanceFunction & Name der genutzten Distanzfunktion. \\
     \hline
     flipVisualization & Wahrheitswert, ob die Visualisierung gespiegelt wird. \\
     \hline
     bodyIdParamName & Bezeichnung des Körperidentifikationsparameters. \\
     \hline
    \end{tabular}
  \end{center}

\section{Programmablauf}
\label{4-Programmablauf}
Im Folgenden wird der Programmablauf beschrieben.
\begin{enumerate}
    \item Der Nutzer startet den \emph{Clustering-Processor}
    und gibt als Startparameter den Pfad der \emph{config-Datei} an.
    \item Der \emph{Processor} nutzt den \emph{Config-Reader}, um die Werte der \emph{Konfigurationdatei} auszulesen
    und speichert diese ab.
    \item Der \emph{Processor} nutzt den \emph{DataReader}, um den Datensatz einzulesen
    und legt die Informationen in geeigneten Objekten ab.
    Beim Kinect-Datensatz sind das die Implementierungen \emph{RecordImpl} und \emph{FrameImpl}
    der entsprechenden Interfaces.
    \item Der \emph{Processor} startet das Clustering durch den Aufruf der \emph{cluster-Methode}
    der \emph{HierarchicalClustering-Klasse}.
    Zu beginn entspricht jeder Record einem eigenen Cluster.
    Die \emph{recordToCluster-Methode} ermöglicht eine Transformation.
    \item Das Clustering nutzt die \emph{\ac{DTW}-Implementierung},
    um paarweise die Kosten zweier Cluster zu berechnen.
    Diese Kosten werden in einer Map abgespeichert, um wiederholte Berechnungen in darauffolgenden Schritten zu vermeiden.
    Als Key der jeweiligen Map-Einträge dient ein Objekt der Klasse ClusterKey.
    \item Die beiden Cluster mit den geringsten Kosten werden zusammengeführt.
    Dazu wird ein neues \emph{Cluster-Objekt} angelegt, dass durch Kombination der beiden Cluster entsteht.
    Konkret wird eines der Cluster in das andere integriert.
    Beim integrierten wird ein boolescher Wert auf \emph{false} gesetzt,
    damit das Cluster in späteren Berechnungsschritten nicht mehr beachtet wird.
    Dabei wird jeweils das Mittel der Attributwerte berechnet und abgelegt.
    Zudem werden die Cluster-Bestandteile abgespeichert.
    Bei allen Komponenten wird ebenfalls das \emph{consider-flag} auf \emph{false} gesetzt,
    damit sie bei zukünftigen Vergleichen nicht mehr berücksichtigt werden.
    \item Schritte 5 und 6 werden so lange wiederholt, bis die geringsten Kosten den vom Nutzer definierten Threshold übersteigen.
    \item Der \emph{Processor} nutzt den \emph{Cluster-Writer}, um alle Cluster der \emph{clusters-Liste}
    in eine Ausgabedatei zu schreiben.
    \item Die gefundenen Cluster werden visualisiert und ebenfalls im Output-Verzeichnis abgelegt.
    \item Die Anwendung terminiert. 

\end{enumerate}


\section{Teilsysteme}
\label{4-Teilsysteme}
ToDo.

\begin{figure}[ht]
    \begin{center}
    \includegraphics[width=\textwidth]{packages.png}
    \end{center}
    \caption{Vorläufiges Paketdiagramm.}
    \label{fig:Packages}
\end{figure}

\begin{figure}[ht]
    \begin{center}
    \includegraphics[width=\textwidth]{classes.png}
    \end{center}
    \caption{Vorläufiges Klassendiagramm.}
    \label{fig:Classes}
\end{figure}
